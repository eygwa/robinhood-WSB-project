{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assembles our dataframes\n",
    "def prepData(symbol):\n",
    "    #read files\n",
    "    f = open(\"stockPrices/{}_prices_2022.json\".format(symbol)) # get rid of stockPrices/ if you dont have it in a folder\n",
    "    price = json.load(f)\n",
    "    stockFrame = pd.read_json(r'sentimentAnalysis/sentiment_analysis_wallstreetbets_{}_posts_2022.json'.format(symbol)) # get rid of stockSentAnalysis/ if you just have it in the folder\n",
    "    f = open(\"topAuthorsPerDay/{}_topAuthorPosts_2022.json\".format(symbol))\n",
    "    topAuthors = json.load(f)\n",
    "    \n",
    "    #setup change in price from day to day\n",
    "    pSetup = dict(OrderedDict(reversed(list(price.items()))))# need to go ordered to reverse it i think\n",
    "    prev = -1\n",
    "    pChange = {}\n",
    "    for key in pSetup:\n",
    "        if(prev==-1): # for the first run just make sure we have some value\n",
    "            prev = float(pSetup[key])\n",
    "        pChange[key] = round(float(pSetup[key]) - prev, 2) # today - yesterday\n",
    "        prev = float(pSetup[key]) # update our previous for next run\n",
    "\n",
    "    #setup price dataframe, i did this at first because like i thought i would concat them but now its like already done\n",
    "    price = pd.DataFrame.from_dict(price, orient= 'index')\n",
    "    price = price.rename(columns={0: 'price'}) #this gives me the prices\n",
    "\n",
    "    #prep sentiment analysis data\n",
    "\n",
    "    #manipulate stock dataframe\n",
    "    for name, dat in stockFrame.items(): # rename them to be strings and in format\n",
    "        stockFrame = stockFrame.rename(columns={name: str(name)[0:10]})\n",
    "    stockFrame = stockFrame.transpose() # easier to put together this way\n",
    "    stockFrame.insert(3, \"price\", float(\"nan\")) # sets them naan to default because we wont always really know\n",
    "\n",
    "    #append them together\n",
    "    for row, dat in stockFrame.iterrows(): # append our items where they can go\n",
    "        if(row in price.index):\n",
    "            stockFrame.loc[row, 'price'] = float(price.loc[row, 'price'])\n",
    "            stockFrame.loc[row, 'day change'] = pChange[row]\n",
    "        if(row in topAuthors):\n",
    "            stockFrame.loc[row, 'top_10_poasters'] = int(topAuthors[row])\n",
    "        else: \n",
    "            stockFrame.loc[row, 'top_10_poasters'] = 0\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #final prep\n",
    "    stockFrame = stockFrame.dropna() # get rid of nan values\n",
    "    stockFrame = pd.get_dummies(stockFrame, columns=['dayAttitude']) # we need dummies for categorical variables\n",
    "\n",
    "    return stockFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>price</th>\n",
       "      <th>top_10_poasters</th>\n",
       "      <th>day change</th>\n",
       "      <th>dayAttitude_negative</th>\n",
       "      <th>dayAttitude_neutual</th>\n",
       "      <th>dayAttitude_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>477.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>477.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>468.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>467.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>466.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           positive negative   price  top_10_poasters  day change  \\\n",
       "2022-01-03        4        1  477.71              0.0        0.00   \n",
       "2022-01-04        4        0  477.55              0.0       -0.16   \n",
       "2022-01-05        7        6  468.38              0.0       -9.17   \n",
       "2022-01-06        4        4  467.94              0.0       -0.44   \n",
       "2022-01-07        7        3  466.09              0.0       -1.85   \n",
       "\n",
       "            dayAttitude_negative  dayAttitude_neutual  dayAttitude_positive  \n",
       "2022-01-03                     0                    0                     1  \n",
       "2022-01-04                     0                    0                     1  \n",
       "2022-01-05                     0                    0                     1  \n",
       "2022-01-06                     0                    1                     0  \n",
       "2022-01-07                     0                    0                     1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = ['SPY', 'NVDA', 'MSFT', 'GOOG', 'GME', 'AI', 'AAPL'] # update this to be whatever symbols ur playing with\n",
    "frames = {}\n",
    "for i in symbols:\n",
    "    frames[i] = prepData(i) # get our dataframes for the stocks we have mined\n",
    "frames['SPY'].head() # just checking sure that we have a dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive                     4\n",
       "negative                     3\n",
       "price                   469.75\n",
       "top_10_poasters            1.0\n",
       "day change                4.24\n",
       "dayAttitude_negative         0\n",
       "dayAttitude_neutual          0\n",
       "dayAttitude_positive         1\n",
       "Name: 2022-01-11, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames['SPY'].transpose()['2022-01-11'] # just using this to check sure that top10 posters got properly appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are just going to run a simple machine learning algorithm on our symbols here and see if any patterns can be found for each of the groups\n",
    "traintest= {}\n",
    "for i in symbols:\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(frames[i].drop(columns = ['day change', 'price']), frames[i]['day change'], test_size=0.2, random_state=47)\n",
    "    traintest[i] = [xtrain, xtest, ytrain, ytest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so first we are going to do regressions on everything and print the results\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression()\n",
    "from sklearn.linear_model import Lasso\n",
    "LA=Lasso(alpha=0.01)\n",
    "\n",
    "\n",
    "\n",
    "modelsLR = {}\n",
    "modelsLA = {}\n",
    "for i in symbols: # create our linear regression models\n",
    "    modelsLR[i] = LR.fit(traintest[i][0], traintest[i][2])\n",
    "    modelsLA[i] = LA.fit(traintest[i][0], traintest[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now test to see if our models are at all accurate:\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "with open('ML_results.txt', 'w') as f:\n",
    "    for i in symbols:\n",
    "       ypredLR = modelsLR[i].predict(traintest[i][1]) # run on our test sets\n",
    "       ypredLA = modelsLA[i].predict(traintest[i][1])\n",
    "\n",
    "       LRr2 = r2_score(traintest[i][3], ypredLR)\n",
    "       LAr2 = r2_score(traintest[i][3], ypredLA)\n",
    "\n",
    "       LRrmse = mean_squared_error(traintest[i][3], ypredLR)\n",
    "       LArmse = mean_squared_error(traintest[i][3], ypredLR)\n",
    "\n",
    "       f.write(\"FOR STOCK: \" + i + '\\n')\n",
    "       f.write(\"\\tLINEAR r2: \" + str(LRr2) + '\\n')\n",
    "       f.write(\"\\tLINEAR MEAN SQUARED ERROR: \" + str(LRrmse) + '\\n')\n",
    "       f.write(\"\\tLASSO r2: \" + str(LAr2) + '\\n')\n",
    "       f.write(\"\\tLASSO MEAN SQUARED ERROR: \" + str(LArmse) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY\n",
      "train: 101\n",
      "test: 26\n",
      "NVDA\n",
      "train: 137\n",
      "test: 35\n",
      "MSFT\n",
      "train: 109\n",
      "test: 28\n",
      "GOOG\n",
      "train: 68\n",
      "test: 18\n",
      "GME\n",
      "train: 199\n",
      "test: 50\n",
      "AI\n",
      "train: 151\n",
      "test: 38\n",
      "AAPL\n",
      "train: 149\n",
      "test: 38\n",
      "130.57142857142858\n",
      "130.57142857142858\n"
     ]
    }
   ],
   "source": [
    "tsum=0\n",
    "tesum=0\n",
    "for i in symbols: \n",
    "    print(i)\n",
    "    print(\"train: \" + str(len(traintest[i][0])))\n",
    "    tsum= tsum + len(traintest[i][0])\n",
    "    print(\"test: \" + str(len(traintest[i][1])))\n",
    "    tesum= tesum + len(traintest[i][1])\n",
    "\n",
    "print(tsum/len(symbols))\n",
    "print(tesum/len(symbols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
